{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Datangels/Machine_Learning_with_PySpark/blob/master/pyspark_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYNNlTodNLbf",
        "colab_type": "text"
      },
      "source": [
        "## **Google Colab configuration & creation the SparkSession Object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FKtDaeR2Z46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuT3jHHAOBvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWpueej7ODZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2cMuUpYNr1e",
        "colab_type": "text"
      },
      "source": [
        "## **Read the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLtRORDQ7PK1",
        "colab_type": "code",
        "outputId": "3ff6a0b4-1edc-4018-ed0b-729cddd5d565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp28j6Rz6CnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_not_clean = spark.read.csv('/content/drive/My Drive/pycharm_colab_training/dataset/books_sentences.csv',inferSchema=True, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWXXJY2UON8Z",
        "colab_type": "text"
      },
      "source": [
        "## **Exploratory Data Analysis**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5HTBvNT_8AZ",
        "colab_type": "code",
        "outputId": "3218f47f-861f-429e-d1c9-5c76ecf621ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print((dataset_not_clean.count(), len(dataset_not_clean.columns)))\n",
        "# dataset_not_clean.printSchema()\n",
        "# dataset_not_clean.describe().show()\n",
        "# print((dataset_not_clean.count(), len(dataset_not_clean.columns)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7087, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0nGAhbvLeUc",
        "colab_type": "text"
      },
      "source": [
        "## **Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWtHfP_SLfzX",
        "colab_type": "code",
        "outputId": "9840dadc-f9a3-427a-c270-02b7f00e23c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "text_df = dataset_not_clean.filter(((dataset_not_clean.Sentiment =='1') | (dataset_not_clean.Sentiment =='0')))\n",
        "text_df = text_df.withColumn(\"Label\", text_df.Sentiment.cast('float')).drop('Sentiment')\n",
        "\n",
        "from pyspark.sql.functions import length\n",
        "from pyspark.sql.functions import rand\n",
        "text_df = text_df.withColumn('length',length(text_df['Review']))\n",
        "text_df.orderBy(rand()).show(10,False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------+-----+------+\n",
            "|Review                                                                  |Label|length|\n",
            "+------------------------------------------------------------------------+-----+------+\n",
            "|Brokeback Mountain was boring.                                          |0.0  |30    |\n",
            "|He's like,'YEAH I GOT ACNE AND I LOVE BROKEBACK MOUNTAIN '..            |1.0  |60    |\n",
            "|Always knows what I want, not guy crazy, hates Harry Potter..           |0.0  |61    |\n",
            "|Harry Potter -- the other two suck.                                     |0.0  |35    |\n",
            "|i love da vinci code....                                                |1.0  |24    |\n",
            "|I am going to start reading the Harry Potter series again because that i|1.0  |72    |\n",
            "|Oh, and Brokeback Mountain is a TERRIBLE movie...                       |0.0  |49    |\n",
            "|da vinci code sucks...                                                  |0.0  |22    |\n",
            "|My dad's being stupid about brokeback mountain...                       |0.0  |49    |\n",
            "|Personally, I love reading Harry Potter books.                          |1.0  |46    |\n",
            "+------------------------------------------------------------------------+-----+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrHBsfc4bvNs",
        "colab_type": "code",
        "outputId": "9c725d9b-141d-42f9-89b4-e7e79fa97b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "\n",
        "tokenization = Tokenizer(inputCol='Review',outputCol='tokens')\n",
        "tokenized_df = tokenization.transform(text_df)\n",
        "stopword_removal = StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')\n",
        "refined_text_df = stopword_removal.transform(tokenized_df)\n",
        "\n",
        "refined_text_df.show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+------+--------------------+--------------------+\n",
            "|              Review|Label|length|              tokens|      refined_tokens|\n",
            "+--------------------+-----+------+--------------------+--------------------+\n",
            "|The Da Vinci Code...|  1.0|    39|[the, da, vinci, ...|[da, vinci, code,...|\n",
            "|this was the firs...|  1.0|    72|[this, was, the, ...|[first, clive, cu...|\n",
            "|i liked the Da Vi...|  1.0|    32|[i, liked, the, d...|[liked, da, vinci...|\n",
            "|i liked the Da Vi...|  1.0|    32|[i, liked, the, d...|[liked, da, vinci...|\n",
            "|I liked the Da Vi...|  1.0|    72|[i, liked, the, d...|[liked, da, vinci...|\n",
            "|that's not even a...|  1.0|    72|[that's, not, eve...|[even, exaggerati...|\n",
            "|I loved the Da Vi...|  1.0|    72|[i, loved, the, d...|[loved, da, vinci...|\n",
            "|i thought da vinc...|  1.0|    57|[i, thought, da, ...|[thought, da, vin...|\n",
            "|The Da Vinci Code...|  1.0|    45|[the, da, vinci, ...|[da, vinci, code,...|\n",
            "|I thought the Da ...|  1.0|    51|[i, thought, the,...|[thought, da, vin...|\n",
            "+--------------------+-----+------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y728jnJacf62",
        "colab_type": "code",
        "outputId": "e269b6c2-3ae0-49ad-d1a5-1b3bba059627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import *\n",
        "len_udf = udf(lambda s: len(s), IntegerType())\n",
        "refined_text_df = refined_text_df.withColumn(\"token_count\",len_udf(col('refined_tokens')))\n",
        "refined_text_df.orderBy(rand()).show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+------+--------------------+--------------------+-----------+\n",
            "|              Review|Label|length|              tokens|      refined_tokens|token_count|\n",
            "+--------------------+-----+------+--------------------+--------------------+-----------+\n",
            "|I hate Harry Potter.|  0.0|    20|[i, hate, harry, ...|[hate, harry, pot...|          3|\n",
            "|I LOVE BROKEBACK ...|  1.0|    26|[i, love, brokeba...|[love, brokeback,...|          3|\n",
            "|Brokeback mountai...|  1.0|    35|[brokeback, mount...|[brokeback, mount...|          3|\n",
            "|by the way, the D...|  0.0|    62|[by, the, way,, t...|[way,, da, vinci,...|          7|\n",
            "|I love Harry Pott...|  1.0|    21|[i, love, harry, ...|[love, harry, pot...|          3|\n",
            "|I want to be here...|  1.0|    72|[i, want, to, be,...|[want, love, harr...|          7|\n",
            "|I love Brokeback ...|  1.0|    29|[i, love, brokeba...|[love, brokeback,...|          3|\n",
            "|Brokeback Mountai...|  0.0|    40|[brokeback, mount...|[brokeback, mount...|          4|\n",
            "|I watched a pirat...|  0.0|    72|[i, watched, a, p...|[watched, pirated...|          8|\n",
            "|DA VINCI CODE IS ...|  1.0|    26|[da, vinci, code,...|[da, vinci, code,...|          4|\n",
            "+--------------------+-----+------+--------------------+--------------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUoHvlo_dBaX",
        "colab_type": "code",
        "outputId": "52abc5de-e53b-4ef8-9684-d7abdda63cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "from pyspark.ml.feature import CountVectorizer\n",
        "count_vec = CountVectorizer(inputCol='refined_tokens',outputCol='features')\n",
        "cv_text_df = count_vec.fit(refined_text_df).transform(refined_text_df)\n",
        "cv_text_df.select(['refined_tokens','token_count','features','Label']).show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+--------------------+-----+\n",
            "|      refined_tokens|token_count|            features|Label|\n",
            "+--------------------+-----------+--------------------+-----+\n",
            "|[da, vinci, code,...|          5|(2302,[0,1,4,43,2...|  1.0|\n",
            "|[first, clive, cu...|          9|(2302,[11,51,229,...|  1.0|\n",
            "|[liked, da, vinci...|          5|(2302,[0,1,4,53,3...|  1.0|\n",
            "|[liked, da, vinci...|          5|(2302,[0,1,4,53,3...|  1.0|\n",
            "|[liked, da, vinci...|          8|(2302,[0,1,4,53,6...|  1.0|\n",
            "|[even, exaggerati...|          6|(2302,[46,229,271...|  1.0|\n",
            "|[loved, da, vinci...|          8|(2302,[0,1,22,30,...|  1.0|\n",
            "|[thought, da, vin...|          7|(2302,[0,1,4,228,...|  1.0|\n",
            "|[da, vinci, code,...|          6|(2302,[0,1,4,33,2...|  1.0|\n",
            "|[thought, da, vin...|          7|(2302,[0,1,4,223,...|  1.0|\n",
            "+--------------------+-----------+--------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XNSqr8JdtaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "model_text_df = cv_text_df.select(['features','token_count','Label'])\n",
        "\n",
        "df_assembler = VectorAssembler(inputCols=['features','token_count'],outputCol='features_vec')\n",
        "model_text_df = df_assembler.transform(model_text_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X93tkp6Gd_QR",
        "colab_type": "text"
      },
      "source": [
        "## **Splitting the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XhEcskreD3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_df, test_df = model_text_df.randomSplit([0.75,0.25])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SWEZZgpeLTB",
        "colab_type": "text"
      },
      "source": [
        "## **Build and Train Linear Regression Mode**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zd1t6rHeLzf",
        "colab_type": "code",
        "outputId": "5bc606fb-ed05-4fe1-90f6-b850cd2d955e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "log_reg = LogisticRegression(featuresCol='features_vec',labelCol='Label').fit(training_df)\n",
        "results = log_reg.evaluate(test_df).predictions\n",
        "results.show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+-----+--------------------+--------------------+--------------------+----------+\n",
            "|            features|token_count|Label|        features_vec|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----------+-----+--------------------+--------------------+--------------------+----------+\n",
            "|(2302,[0,1,4,5,64...|          6|  1.0|(2303,[0,1,4,5,64...|[-17.648497042873...|[2.16448764406048...|       1.0|\n",
            "|(2302,[0,1,4,5,22...|          9|  1.0|(2303,[0,1,4,5,22...|[-8.7506228304995...|[1.58337586536483...|       1.0|\n",
            "|(2302,[0,1,4,5,30...|          5|  1.0|(2303,[0,1,4,5,30...|[-20.437778527709...|[1.33041018958616...|       1.0|\n",
            "|(2302,[0,1,4,5,36...|          5|  1.0|(2303,[0,1,4,5,36...|[-12.212404455274...|[4.96841628432399...|       1.0|\n",
            "|(2302,[0,1,4,5,65...|          5|  1.0|(2303,[0,1,4,5,65...|[-16.296294485445...|[8.36775956994756...|       1.0|\n",
            "|(2302,[0,1,4,11,4...|          7|  1.0|(2303,[0,1,4,11,4...|[-9.6682907018195...|[6.32538882645125...|       1.0|\n",
            "|(2302,[0,1,4,12,1...|          8|  1.0|(2303,[0,1,4,12,1...|[-18.904741217060...|[6.16275928866616...|       1.0|\n",
            "|(2302,[0,1,4,12,2...|          7|  1.0|(2303,[0,1,4,12,2...|[-15.783494847384...|[1.39738224852054...|       1.0|\n",
            "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-18.298624061942...|[1.12981812756316...|       1.0|\n",
            "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-18.298624061942...|[1.12981812756316...|       1.0|\n",
            "+--------------------+-----------+-----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhPrIhwJeqX4",
        "colab_type": "text"
      },
      "source": [
        "## **Evaluate Model on Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-tiBt6zesZ8",
        "colab_type": "code",
        "outputId": "2b69f822-577e-48cb-b7e8-a1810ffb923f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "true_postives = results[(results.Label == 1) & (results.prediction == 1)].count()\n",
        "true_negatives = results[(results.Label == 0) & (results.prediction == 0)].count()\n",
        "false_positives = results[(results.Label == 0) & (results.prediction == 1)].count()\n",
        "false_negatives = results[(results.Label == 1) & (results.prediction == 0)].count()\n",
        "\n",
        "recall = float(true_postives)/(true_postives + false_negatives)\n",
        "print(\"Recall: \" + str(recall))\n",
        "precision = float(true_postives) / (true_postives + false_positives)\n",
        "print(\"Precision: \" + str(precision))\n",
        "accuracy = float((true_postives + true_negatives) /(results.count()))\n",
        "print(\"Accuracy: \" + str(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall: 0.9847715736040609\n",
            "Precision: 0.967098703888335\n",
            "Accuracy: 0.9732292247629671\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}